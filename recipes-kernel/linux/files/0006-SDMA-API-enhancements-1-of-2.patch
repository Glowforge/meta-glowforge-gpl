From 1414c0c674316c7eb58e396311c36630cfab33f6 Mon Sep 17 00:00:00 2001
From: Matt Sarnoff <matt@glowforge.com>
Date: Fri, 8 May 2020 10:41:11 -0700
Subject: [PATCH] SDMA API enhancements

From linux-glowforge 0e02411df3fd89743e60d44941f3a54778e8d509
---
 drivers/dma/imx-sdma.c                     | 350 +++++++++++++++++++-
 include/linux/platform_data/dma-imx-sdma.h | 351 +++++++++++++++++++++
 2 files changed, 685 insertions(+), 16 deletions(-)

diff --git a/drivers/dma/imx-sdma.c b/drivers/dma/imx-sdma.c
index dd9b3ff9f7bf..e077b4dfe6f2 100644
--- a/drivers/dma/imx-sdma.c
+++ b/drivers/dma/imx-sdma.c
@@ -10,6 +10,9 @@
 //
 // Copyright 2004-2016 Freescale Semiconductor, Inc. All Rights Reserved.
 // Copyright 2018 NXP.
+//
+// Modifications to expose functionality to modules are
+// copyright (C) 2015-2018 Glowforge, Inc. <opensource@glowforge.com>
 
 #include <linux/init.h>
 #include <linux/iopoll.h>
@@ -193,6 +196,7 @@
 #define SDMA_WATERMARK_LEVEL_SW_DONE	BIT(23)
 #define SDMA_WATERMARK_LEVEL_SW_DONE_SEL_OFF 24
 
+#if 0
 /*
  * Mode/Count of data node descriptors - IPCv2
  */
@@ -312,6 +316,7 @@ struct sdma_context_data {
 
 
 struct sdma_engine;
+#endif
 
 /**
  * struct sdma_desc - descriptor structor for one transfer
@@ -397,9 +402,13 @@ struct sdma_channel {
 	unsigned int			fifo_num;
 	bool				sw_done;
 	u32				sw_done_sel;
+	struct tasklet_struct		custom_cb_tasklet;
+	dma_async_tx_callback		custom_callback;
+	void				*custom_callback_param;
 };
 
 #define IMX_DMA_SG_LOOP		BIT(0)
+#define IMX_DMA_CUSTOM_CALLBACK	BIT(1)
 
 #define MAX_DMA_CHANNELS 32
 #define MXC_SDMA_DEFAULT_PRIORITY 1
@@ -483,12 +492,23 @@ struct sdma_engine {
 	bool				fw_loaded;
 	u32				fw_fail;
 	unsigned short			ram_code_start;
+	void				*tiny_datamem_buf;
+	dma_addr_t			tiny_datamem_buf_phys;
 };
 
 static int sdma_config_write(struct dma_chan *chan,
 		       struct dma_slave_config *dmaengine_cfg,
 		       enum dma_transfer_direction direction);
 
+/**
+ * If nonzero, sdma_write_datamem()/sdma_fetch_datamem()
+ * use a single preallocated temporary buffer for transfers whose size is
+ * less than or equal to this value.
+ */
+#define TINY_DATAMEM_BUF_SIZE	PAGE_SIZE
+
+static struct sdma_engine *sdma_singleton = NULL;
+
 static struct sdma_driver_data sdma_imx31 = {
 	.chnenbl0 = SDMA_CHNENBL0_IMX31,
 	.num_events = 32,
@@ -687,13 +707,21 @@ MODULE_DEVICE_TABLE(of, sdma_dt_ids);
 #define SDMA_H_CONFIG_ACR	BIT(4)  /* indicates if AHB freq /core freq = 2 or 1 */
 #define SDMA_H_CONFIG_CSM	(3)       /* indicates which context switch mode is selected*/
 
+/* returns an address in data space (32-bit words) */
+/* (mjs) exposed to modules */
+u32 sdma_channel_context_base(int ch)
+{
+	return 2048 + (sizeof(struct sdma_context_data) / 4) * ch;
+}
+EXPORT_SYMBOL(sdma_channel_context_base);
+
 static inline u32 chnenbl_ofs(struct sdma_engine *sdma, unsigned int event)
 {
 	u32 chnenbl0 = sdma->drvdata->chnenbl0;
 	return chnenbl0 + event * 4;
 }
 
-static int sdma_config_ownership(struct sdma_channel *sdmac,
+int sdma_config_ownership(struct sdma_channel *sdmac,
 		bool event_override, bool mcu_override, bool dsp_override)
 {
 	struct sdma_engine *sdma = sdmac->sdma;
@@ -728,21 +756,28 @@ static int sdma_config_ownership(struct sdma_channel *sdmac,
 
 	return 0;
 }
+EXPORT_SYMBOL(sdma_config_ownership);
 
-static void sdma_enable_channel(struct sdma_engine *sdma, int channel)
+static void sdma_enable_channel_number(struct sdma_engine *sdma, int channel)
 {
 	writel(BIT(channel), sdma->regs + SDMA_H_START);
 }
 
+void sdma_enable_channel(struct sdma_channel *sdmac)
+{
+	sdma_enable_channel_number(sdmac->sdma, sdmac->channel);
+}
+EXPORT_SYMBOL(sdma_enable_channel);
+
 /*
  * sdma_run_channel0 - run a channel and wait till it's done
  */
-static int sdma_run_channel0(struct sdma_engine *sdma)
+int sdma_run_channel0(struct sdma_engine *sdma)
 {
 	int ret;
 	u32 reg;
 
-	sdma_enable_channel(sdma, 0);
+	sdma_enable_channel_number(sdma, 0);
 
 	ret = readl_relaxed_poll_timeout_atomic(sdma->regs + SDMA_H_STATSTOP,
 						reg, !(reg & 1), 1, 500);
@@ -758,8 +793,9 @@ static int sdma_run_channel0(struct sdma_engine *sdma)
 
 	return ret;
 }
+EXPORT_SYMBOL(sdma_run_channel0);
 
-static int sdma_load_script(struct sdma_engine *sdma, void *buf, int size,
+int sdma_load_script(struct sdma_engine *sdma, void *buf, int size,
 		u32 address)
 {
 	struct sdma_buffer_descriptor *bd0 = sdma->bd0;
@@ -797,8 +833,123 @@ static int sdma_load_script(struct sdma_engine *sdma, void *buf, int size,
 
 	return ret;
 }
+EXPORT_SYMBOL(sdma_load_script);
+
+int sdma_write_datamem(struct sdma_engine *sdma, void *buf, int size,
+		u32 address)
+{
+	struct sdma_buffer_descriptor *bd0 = sdma->bd0;
+	void *buf_virt;
+	dma_addr_t buf_phys;
+	int ret;
+	unsigned long flags;
+	bool tiny = (size <= TINY_DATAMEM_BUF_SIZE);
+
+	if (!tiny) {
+		if (sdma->iram_pool)
+			buf_virt = gen_pool_dma_alloc(sdma->iram_pool, size, &buf_phys);
+		else
+			buf_virt = dma_alloc_coherent(sdma->dev, size, &buf_phys,
+					      	GFP_KERNEL);
+		if (!buf_virt)
+			return -ENOMEM;
+	} else {
+		buf_virt = sdma->tiny_datamem_buf;
+		buf_phys = sdma->tiny_datamem_buf_phys;
+	}
+
+	spin_lock_irqsave(&sdma->channel_0_lock, flags);
+
+	bd0->mode.command = C0_SETDM;
+	bd0->mode.status = BD_DONE | BD_WRAP | BD_EXTD;
+	bd0->mode.count = size / 4;
+	bd0->buffer_addr = buf_phys;
+	bd0->ext_buffer_addr = address;
+
+	memcpy(buf_virt, buf, size);
+
+	ret = sdma_run_channel0(sdma);
+
+	spin_unlock_irqrestore(&sdma->channel_0_lock, flags);
+
+	if (!tiny) {
+		if (sdma->iram_pool)
+			gen_pool_free(sdma->iram_pool, (unsigned long)buf_virt,
+					size);
+		else
+			dma_free_coherent(sdma->dev, size, buf_virt, buf_phys);
+	}
+
+	return ret;
+}
+EXPORT_SYMBOL(sdma_write_datamem);
 
-static void sdma_event_enable(struct sdma_channel *sdmac, unsigned int event)
+int sdma_fetch_datamem(struct sdma_engine *sdma, void *buf, int size,
+		u32 address)
+{
+	struct sdma_buffer_descriptor *bd0 = sdma->bd0;
+	void *buf_virt;
+	dma_addr_t buf_phys;
+	int ret;
+	unsigned long flags;
+	bool tiny = (size <= TINY_DATAMEM_BUF_SIZE);
+
+	if (!tiny) {
+		if (sdma->iram_pool)
+			buf_virt = gen_pool_dma_alloc(sdma->iram_pool, size, &buf_phys);
+		else
+			buf_virt = dma_alloc_coherent(sdma->dev, size, &buf_phys,
+					GFP_KERNEL);
+		if (!buf_virt)
+			return -ENOMEM;
+	} else {
+		buf_virt = sdma->tiny_datamem_buf;
+		buf_phys = sdma->tiny_datamem_buf_phys;
+	}
+	spin_lock_irqsave(&sdma->channel_0_lock, flags);
+
+	bd0->mode.command = C0_GETDM;
+	bd0->mode.status = BD_DONE | BD_WRAP | BD_EXTD;
+	bd0->mode.count = size / 4;
+	bd0->buffer_addr = buf_phys;
+	bd0->ext_buffer_addr = address;
+
+	ret = sdma_run_channel0(sdma);
+
+	memcpy(buf, buf_virt, size);
+
+	spin_unlock_irqrestore(&sdma->channel_0_lock, flags);
+
+	if (!tiny) {
+		if (sdma->iram_pool)
+			gen_pool_free(sdma->iram_pool, (unsigned long)buf_virt,
+					size);
+		else
+			dma_free_coherent(sdma->dev, size, buf_virt, buf_phys);
+	}
+
+	return ret;
+}
+EXPORT_SYMBOL(sdma_fetch_datamem);
+
+int sdma_fetch_partial_context(struct sdma_channel *sdmac, void *buf,
+    u32 byte_offset,
+    u32 num_bytes)
+{
+  static const u32 csz = sizeof(struct sdma_context_data);
+  u32 addr;
+  if (num_bytes > csz || num_bytes == 0 ||
+      byte_offset >= csz || byte_offset+num_bytes > csz ||
+      num_bytes % sizeof(u32) || byte_offset % sizeof(u32)) {
+    dev_err(sdmac->sdma->dev, "%s: invalid offset/length", __func__);
+    return -EINVAL;
+  }
+  addr = sdma_channel_context_base(sdmac->channel) + byte_offset/sizeof(u32);
+  return sdma_fetch_datamem(sdmac->sdma, buf, num_bytes, addr);
+}
+EXPORT_SYMBOL(sdma_fetch_partial_context);
+
+void sdma_event_enable(struct sdma_channel *sdmac, unsigned int event)
 {
 	struct sdma_engine *sdma = sdmac->sdma;
 	int channel = sdmac->channel;
@@ -824,8 +975,9 @@ static void sdma_event_enable(struct sdma_channel *sdmac, unsigned int event)
 	}
 
 }
+EXPORT_SYMBOL(sdma_event_enable);
 
-static void sdma_event_disable(struct sdma_channel *sdmac, unsigned int event)
+void sdma_event_disable(struct sdma_channel *sdmac, unsigned int event)
 {
 	struct sdma_engine *sdma = sdmac->sdma;
 	int channel = sdmac->channel;
@@ -836,6 +988,7 @@ static void sdma_event_disable(struct sdma_channel *sdmac, unsigned int event)
 	__clear_bit(channel, &val);
 	writel_relaxed(val, sdma->regs + chnenbl);
 }
+EXPORT_SYMBOL(sdma_event_disable);
 
 static struct sdma_desc *to_sdma_desc(struct dma_async_tx_descriptor *t)
 {
@@ -863,7 +1016,7 @@ static void sdma_start_desc(struct sdma_channel *sdmac)
 
 	sdma->channel_control[channel].base_bd_ptr = desc->bd_phys;
 	sdma->channel_control[channel].current_bd_ptr = desc->bd_phys;
-	sdma_enable_channel(sdma, sdmac->channel);
+	sdma_enable_channel_number(sdma, sdmac->channel);
 }
 
 static void sdma_update_channel_loop(struct sdma_channel *sdmac)
@@ -941,6 +1094,14 @@ static void mxc_sdma_handle_channel_normal(struct sdma_channel *data)
 		sdmac->status = DMA_COMPLETE;
 }
 
+static void custom_cb_tasklet(unsigned long data)
+{
+	struct sdma_channel *sdmac = (struct sdma_channel *) data;
+	if (sdmac->custom_callback)
+		sdmac->custom_callback(sdmac->custom_callback_param);
+}
+
+
 static irqreturn_t sdma_int_handler(int irq, void *dev_id)
 {
 	struct sdma_engine *sdma = dev_id;
@@ -959,6 +1120,9 @@ static irqreturn_t sdma_int_handler(int irq, void *dev_id)
 		spin_lock(&sdmac->vc.lock);
 		desc = sdmac->desc;
 		if (desc) {
+			if (sdmac->flags & IMX_DMA_CUSTOM_CALLBACK)
+				tasklet_schedule(&sdmac->custom_cb_tasklet);
+
 			if (sdmac->flags & IMX_DMA_SG_LOOP) {
 				if (sdmac->peripheral_type != IMX_DMATYPE_HDMI)
 					sdma_update_channel_loop(sdmac);
@@ -1142,7 +1306,7 @@ static int sdma_load_context(struct sdma_channel *sdmac)
 	bd0->mode.status = BD_DONE | BD_WRAP | BD_EXTD;
 	bd0->mode.count = sizeof(*context) / 4;
 	bd0->buffer_addr = sdma->context_phys;
-	bd0->ext_buffer_addr = 2048 + (sizeof(*context) / 4) * channel;
+	bd0->ext_buffer_addr = sdma_channel_context_base(channel);
 	ret = sdma_run_channel0(sdma);
 
 	spin_unlock_irqrestore(&sdma->channel_0_lock, flags);
@@ -1180,9 +1344,33 @@ static struct sdma_channel *to_sdma_chan(struct dma_chan *chan)
 	return container_of(chan, struct sdma_channel, vc.chan);
 }
 
-static int sdma_disable_channel(struct dma_chan *chan)
+int sdma_load_context_raw(struct sdma_channel *sdmac,
+		struct sdma_context_data *context)
+{
+	return sdma_load_partial_context(sdmac, context, 0, sizeof(*context));
+}
+EXPORT_SYMBOL(sdma_load_context_raw);
+
+int sdma_load_partial_context(struct sdma_channel *sdmac,
+    struct sdma_context_data *context,
+    u32 byte_offset,
+    u32 num_bytes)
+{
+  static const u32 csz = sizeof(*context);
+  u32 addr;
+  if (num_bytes > csz || num_bytes == 0 ||
+      byte_offset >= csz || byte_offset+num_bytes > csz ||
+      num_bytes % sizeof(u32) || byte_offset % sizeof(u32)) {
+    dev_err(sdmac->sdma->dev, "%s: invalid offset/length", __func__);
+    return -EINVAL;
+  }
+  addr = sdma_channel_context_base(sdmac->channel) + byte_offset/sizeof(u32);
+  return sdma_write_datamem(sdmac->sdma, context, num_bytes, addr);
+}
+EXPORT_SYMBOL(sdma_load_partial_context);
+
+int sdma_disable_channel(struct sdma_channel *sdmac)
 {
-	struct sdma_channel *sdmac = to_sdma_chan(chan);
 	struct sdma_engine *sdma = sdmac->sdma;
 	int channel = sdmac->channel;
 
@@ -1191,6 +1379,8 @@ static int sdma_disable_channel(struct dma_chan *chan)
 
 	return 0;
 }
+EXPORT_SYMBOL(sdma_disable_channel);
+
 static void sdma_channel_terminate_work(struct work_struct *work)
 {
 	struct sdma_channel *sdmac = container_of(work, struct sdma_channel,
@@ -1217,7 +1407,7 @@ static int sdma_disable_channel_async(struct dma_chan *chan)
 {
 	struct sdma_channel *sdmac = to_sdma_chan(chan);
 
-	sdma_disable_channel(chan);
+	sdma_disable_channel(sdmac);
 
 	if (sdmac->desc)
 		schedule_work(&sdmac->terminate_worker);
@@ -1303,7 +1493,7 @@ static int sdma_config_channel(struct dma_chan *chan)
 {
 	struct sdma_channel *sdmac = to_sdma_chan(chan);
 
-	sdma_disable_channel(chan);
+	sdma_disable_channel(sdmac);
 
 	sdmac->event_mask[0] = 0;
 	sdmac->event_mask[1] = 0;
@@ -1357,7 +1547,7 @@ static int sdma_config_channel(struct dma_chan *chan)
 	return 0;
 }
 
-static int sdma_set_channel_priority(struct sdma_channel *sdmac,
+int sdma_set_channel_priority(struct sdma_channel *sdmac,
 		unsigned int priority)
 {
 	struct sdma_engine *sdma = sdmac->sdma;
@@ -1372,6 +1562,7 @@ static int sdma_set_channel_priority(struct sdma_channel *sdmac,
 
 	return 0;
 }
+EXPORT_SYMBOL(sdma_set_channel_priority);
 
 static int sdma_request_channel0(struct sdma_engine *sdma)
 {
@@ -1398,6 +1589,22 @@ static int sdma_request_channel0(struct sdma_engine *sdma)
 	return ret;
 }
 
+void sdma_set_channel_interrupt_callback(struct sdma_channel *sdmac,
+		dma_async_tx_callback int_cb,
+		void *cb_param)
+{
+	unsigned long flags;
+	spin_lock_irqsave(&sdmac->vc.lock, flags);
+	if (int_cb)
+		sdmac->flags |= IMX_DMA_CUSTOM_CALLBACK;
+	else
+		sdmac->flags &= ~IMX_DMA_CUSTOM_CALLBACK;
+	sdmac->custom_callback = int_cb;
+	sdmac->custom_callback_param = cb_param;
+	spin_unlock_irqrestore(&sdmac->vc.lock, flags);
+}
+EXPORT_SYMBOL(sdma_set_channel_interrupt_callback);
+
 
 static int sdma_alloc_bd(struct sdma_desc *desc)
 {
@@ -2118,6 +2325,21 @@ static int sdma_init(struct sdma_engine *sdma)
 		goto err_dma_alloc;
 	}
 
+#if TINY_DATAMEM_BUF_SIZE
+	if (sdma->iram_pool)
+		sdma->tiny_datamem_buf = gen_pool_dma_alloc(sdma->iram_pool,
+				TINY_DATAMEM_BUF_SIZE, &sdma->tiny_datamem_buf_phys);
+	else
+		sdma->tiny_datamem_buf = dma_alloc_coherent(sdma->dev,
+				TINY_DATAMEM_BUF_SIZE,
+				&sdma->tiny_datamem_buf_phys, GFP_KERNEL);
+		
+	if (!sdma->tiny_datamem_buf) {
+		ret = -ENOMEM;
+		goto err_dma_alloc;
+	}
+#endif
+
 	sdma->context = (void *)sdma->channel_control +
 		MAX_DMA_CHANNELS * sizeof (struct sdma_channel_control);
 	sdma->context_phys = ccb_phys +
@@ -2304,6 +2526,8 @@ static int sdma_probe(struct platform_device *pdev)
 		sdmac->sdma = sdma;
 
 		sdmac->channel = i;
+		tasklet_init(&sdmac->custom_cb_tasklet, custom_cb_tasklet,
+			     (unsigned long) sdmac);
 		sdmac->vc.desc_free = sdma_desc_free;
 		INIT_WORK(&sdmac->terminate_worker,
 				sdma_channel_terminate_work);
@@ -2429,14 +2653,22 @@ static int sdma_remove(struct platform_device *pdev)
 	kfree(sdma->script_addrs);
 	clk_unprepare(sdma->clk_ahb);
 	clk_unprepare(sdma->clk_ipg);
-	/* Kill the tasklet */
+	/* Kill the tasklets */
 	for (i = 0; i < MAX_DMA_CHANNELS; i++) {
 		struct sdma_channel *sdmac = &sdma->channel[i];
 
 		tasklet_kill(&sdmac->vc.task);
+		tasklet_kill(&sdmac->custom_cb_tasklet);
 		sdma_free_chan_resources(&sdmac->vc.chan);
 	}
-
+#if TINY_DATAMEM_BUF_SIZE
+	if (sdma->iram_pool)
+		gen_pool_free(sdma->iram_pool, (unsigned long)sdma->tiny_datamem_buf,
+			TINY_DATAMEM_BUF_SIZE);
+	else
+		dma_free_coherent(sdma->dev, TINY_DATAMEM_BUF_SIZE,
+			sdma->tiny_datamem_buf, sdma->tiny_datamem_buf_phys);
+#endif
 	platform_set_drvdata(pdev, NULL);
 	return 0;
 }
@@ -2552,6 +2784,92 @@ static int sdma_resume(struct device *dev)
 }
 #endif
 
+struct sdma_channel *sdma_get_channel(struct sdma_engine *sdma, int channel)
+{
+	if (channel < 0 || channel >= MAX_DMA_CHANNELS) {
+		return NULL;
+	}
+	return &sdma->channel[channel];
+}
+EXPORT_SYMBOL(sdma_get_channel);
+
+/* (mjs) convenience function for initializing a channel as
+ * host-triggered or event-triggered
+ * external=false: channel started by host, HO[i]=0, EO[i]=1
+ * external=true: channel started by event, HO[i]=1, EO[i]=0 */
+void sdma_setup_channel(struct sdma_channel *sdmac, bool external)
+{
+	sdma_disable_channel(sdmac);
+	sdma_config_ownership(sdmac,
+		external,   /* event override */
+		!external,  /* host override */
+		false);     /* always false */
+}
+EXPORT_SYMBOL(sdma_setup_channel);
+
+struct sdma_engine *sdma_engine_get(void)
+{
+	return sdma_singleton;
+}
+EXPORT_SYMBOL(sdma_engine_get);
+
+ssize_t sdma_print_context(struct sdma_engine *sdma, int channel, char *buf)
+{
+	static const char *regnames[] = {
+		" r0", " r1", " r2", " r3", " r4", " r5", " r6", " r7",
+		"mda", "msa", " ms", " md", "pda", "psa", " ps", " pd",
+		" ca", " cs", "dda", "dsa", " ds", " dd", "sc0", "sc1",
+		"sc2", "sc3", "sc4", "sc5", "sc6", "sc7"
+	};
+
+	struct sdma_context_data *context;
+	u32 context_addr = sdma_channel_context_base(channel);
+	u32 context_size = sizeof(*context);
+	u32 *regptr;
+	int ret;
+	int i;
+	ssize_t outlen = 0;
+
+	context = kzalloc(context_size, GFP_ATOMIC);
+	if (!context) {
+		return -ENOMEM;
+	}
+
+	ret = sdma_fetch_datamem(sdma, context, context_size, context_addr);
+	if (ret) {
+		return ret;
+	}
+
+	outlen += scnprintf(buf+outlen, PAGE_SIZE-outlen,
+		"pc=%04x rpc=%04x spc=%04x epc=%04x\n",
+		context->channel_state.pc,
+		context->channel_state.rpc,
+		context->channel_state.spc,
+		context->channel_state.epc
+	);
+
+	outlen += scnprintf(buf+outlen, PAGE_SIZE-outlen,
+		"Flags: t=%d sf=%d df=%d lm=%d\n",
+		(context->channel_state.t != 0),
+		(context->channel_state.sf != 0),
+		(context->channel_state.df != 0),
+		(context->channel_state.lm != 0)
+	);
+
+	regptr = &context->gReg[0];
+	for (i = 0; i < ARRAY_SIZE(regnames); i++) {
+		outlen += scnprintf(buf+outlen, PAGE_SIZE-outlen,
+			"%s=%08x%c",
+			regnames[i],
+			regptr[i],
+			((i % 6) == 5) ? '\n' : ' ');
+	}
+	outlen += scnprintf(buf+outlen, PAGE_SIZE-outlen, "\n");
+	kfree(context);
+	return outlen;
+}
+EXPORT_SYMBOL(sdma_print_context);
+
 static const struct dev_pm_ops sdma_pm_ops = {
 	SET_LATE_SYSTEM_SLEEP_PM_OPS(sdma_suspend, sdma_resume)
 };
diff --git a/include/linux/platform_data/dma-imx-sdma.h b/include/linux/platform_data/dma-imx-sdma.h
index e12d2e8c246b..11b91f080150 100644
--- a/include/linux/platform_data/dma-imx-sdma.h
+++ b/include/linux/platform_data/dma-imx-sdma.h
@@ -1,7 +1,14 @@
 /* SPDX-License-Identifier: GPL-2.0 */
+/**
+ * Modifications to expose functionality to modules are
+ * copyright (C) 2015-2018 Glowforge, Inc. <opensource@glowforge.com>
+ */
+
 #ifndef __MACH_MXC_SDMA_H__
 #define __MACH_MXC_SDMA_H__
 
+#include <linux/dmaengine.h>
+
 /**
  * struct sdma_script_start_addrs - SDMA script start pointers
  *
@@ -72,4 +79,348 @@ struct sdma_platform_data {
 	struct sdma_script_start_addrs *script_addrs;
 };
 
+/*
+ * Mode/Count of data node descriptors - IPCv2
+ */
+struct sdma_mode_count {
+#define SDMA_BD_MAX_CNT	0xffff
+	u32 count   : 16; /* size of the buffer pointed by this BD */
+	u32 status  :  8; /* E,R,I,C,W,D status bits stored here */
+	u32 command :  8; /* command mostly used for channel 0 */
+};
+
+/*
+ * Buffer descriptor
+ */
+struct sdma_buffer_descriptor {
+	struct sdma_mode_count  mode;
+	u32 buffer_addr;	/* address of the buffer described */
+	u32 ext_buffer_addr;	/* extended buffer address */
+} __attribute__ ((packed));
+
+/**
+ * struct sdma_channel_control - Channel control Block
+ *
+ * @current_bd_ptr	current buffer descriptor processed
+ * @base_bd_ptr		first element of buffer descriptor array
+ * @unused		padding. The SDMA engine expects an array of 128 byte
+ *			control blocks
+ */
+struct sdma_channel_control {
+	u32 current_bd_ptr;
+	u32 base_bd_ptr;
+	u32 unused[2];
+} __attribute__ ((packed));
+
+/**
+ * struct sdma_state_registers - SDMA context for a channel
+ *
+ * @pc:		program counter
+ * @unused1:	unused
+ * @t:		test bit: status of arithmetic & test instruction
+ * @rpc:	return program counter
+ * @unused0:	unused
+ * @sf:		source fault while loading data
+ * @spc:	loop start program counter
+ * @unused2:	unused
+ * @df:		destination fault while storing data
+ * @epc:	loop end program counter
+ * @lm:		loop mode
+ */
+struct sdma_state_registers {
+	u32 pc     :14;
+	u32 unused1: 1;
+	u32 t      : 1;
+	u32 rpc    :14;
+	u32 unused0: 1;
+	u32 sf     : 1;
+	u32 spc    :14;
+	u32 unused2: 1;
+	u32 df     : 1;
+	u32 epc    :14;
+	u32 lm     : 2;
+} __attribute__ ((packed));
+
+/**
+ * struct sdma_context_data - sdma context specific to a channel
+ *
+ * @channel_state:	channel state bits
+ * @gReg:		general registers
+ * @mda:		burst dma destination address register
+ * @msa:		burst dma source address register
+ * @ms:			burst dma status register
+ * @md:			burst dma data register
+ * @pda:		peripheral dma destination address register
+ * @psa:		peripheral dma source address register
+ * @ps:			peripheral dma status register
+ * @pd:			peripheral dma data register
+ * @ca:			CRC polynomial register
+ * @cs:			CRC accumulator register
+ * @dda:		dedicated core destination address register
+ * @dsa:		dedicated core source address register
+ * @ds:			dedicated core status register
+ * @dd:			dedicated core data register
+ * @scratch0:		1st word of dedicated ram for context switch
+ * @scratch1:		2nd word of dedicated ram for context switch
+ * @scratch2:		3rd word of dedicated ram for context switch
+ * @scratch3:		4th word of dedicated ram for context switch
+ * @scratch4:		5th word of dedicated ram for context switch
+ * @scratch5:		6th word of dedicated ram for context switch
+ * @scratch6:		7th word of dedicated ram for context switch
+ * @scratch7:		8th word of dedicated ram for context switch
+ */
+struct sdma_context_data {
+	struct sdma_state_registers  channel_state;
+	u32  gReg[8];
+	u32  mda;
+	u32  msa;
+	u32  ms;
+	u32  md;
+	u32  pda;
+	u32  psa;
+	u32  ps;
+	u32  pd;
+	u32  ca;
+	u32  cs;
+	u32  dda;
+	u32  dsa;
+	u32  ds;
+	u32  dd;
+	u32  scratch0;
+	u32  scratch1;
+	u32  scratch2;
+	u32  scratch3;
+	u32  scratch4;
+	u32  scratch5;
+	u32  scratch6;
+	u32  scratch7;
+} __attribute__ ((packed));
+
+#define NUM_BD (int)(PAGE_SIZE / sizeof(struct sdma_buffer_descriptor))
+
+struct sdma_engine;
+
+struct sdma_channel;
+
+/**
+ * sdma_engine_get() - returns a pointer to the global SDMA engine
+ *
+ * Return: pointer to the sdma_engine object
+ */
+struct sdma_engine *sdma_engine_get(void);
+
+/**
+ * sdma_get_channel() - returns a pointer to the numbered SDMA channel
+ * @sdma:	pointer to the sdma_engine object
+ * @channel:	channel number from 0-31
+ *
+ * Return: pointer to channel object, or NULL
+ */
+struct sdma_channel *sdma_get_channel(struct sdma_engine *sdma, int channel);
+
+/**
+ * sdma_set_channel_interrupt_callback() - sets a custom interrupt handler
+ * @sdmac:	pointer to sdma_channel object
+ * @int_cb:	callback function to register
+ * @cb_param:	user-defined object passed when the callback is invoked
+ *
+ * Sets a function to be called when a custom SDMA script triggers an interrupt
+ * (e.g. with a "done 3" instruction).
+ * The function is executed in tasklet (atomic) context.
+ */
+void sdma_set_channel_interrupt_callback(struct sdma_channel *sdmac,
+		dma_async_tx_callback int_cb,
+		void *cb_param);
+
+/**
+ * sdma_set_channel_priority() - sets the channel's execution priority
+ * @sdmac:	pointer to sdma_channel object
+ * @priority:	priority, from 0 (disabled) to 7 (highest)
+ *
+ * Setting a nonzero priority may cause the channel's script to begin executing,
+ * depending on how it is configured.
+ * Priority 7 is used by channel 0 for loading scripts/context. Typically,
+ * channel 0 should be the only channel with priority 7.
+ *
+ * Return: 0 on success, nonzero otherwise
+ */
+int sdma_set_channel_priority(struct sdma_channel *sdmac,
+		unsigned int priority);
+
+/**
+ * sdma_config_ownership() - configures ownership of a channel
+ * @sdmac:		pointer to sdma_channel object
+ * @event_override:	if true, script can be triggered by an external event
+ * @mcu_override:	if true, script can be triggered by the CPU
+ * @dsp_override:	unused on i.MX6, always pass false
+ *
+ * Return: 0 on success, nonzero otherwise
+ */
+int sdma_config_ownership(struct sdma_channel *sdmac, bool event_override,
+		bool mcu_override, bool dsp_override);
+
+/**
+ * sdma_setup_channel() - convenience function for setting channel ownership
+ * @sdmac:	pointer to sdma_channel object
+ * @external:	if true, script is triggered by an external event,
+ *		if false, script is triggered by the CPU
+ */
+void sdma_setup_channel(struct sdma_channel *sdmac, bool external);
+
+/**
+ * sdma_enable_channel() - allows a channel to be run
+ * @sdmac:	pointer to sdma_channel object
+ */
+void sdma_enable_channel(struct sdma_channel *sdmac);
+
+/**
+ * sdma_disable_channel() - prevents a channel from being run
+ * @sdmac:	pointer to sdma_channel object
+ * Return: 0
+ */
+int sdma_disable_channel(struct sdma_channel *sdmac);
+
+/**
+ * sdma_event_enable() - allows a channel to be triggered by the numbered event
+ * @sdmac:	pointer to sdma_channel object
+ * @event:	event number (see reference manual)
+ */
+void sdma_event_enable(struct sdma_channel *sdmac, unsigned int event);
+
+/**
+ * sdma_event_disable() - prevents a channel from being triggered by an event
+ * @sdmac:	pointer to sdma_channel object
+ * @event:	event number (see reference manual)
+ */
+void sdma_event_disable(struct sdma_channel *sdmac, unsigned int event);
+
+/* address should be in program space (halfword addressing) */
+
+/**
+ * sdma_load_script() - copies script from ARM memory to SDMA memory
+ * @sdma:	pointer to sdma_engine object
+ * @buf:	start of script
+ * @size:	size of script in bytes
+ * @address:	destination address in SDMA program space
+ *		(using halfword addressing)
+ *
+ * Return: 0 on success, nonzero on error
+ */
+int sdma_load_script(struct sdma_engine *sdma, void *buf, int size,
+		u32 address);
+
+/**
+ * sdma_load_context_raw() - loads context for a channel running a custom script
+ * @sdmac:	pointer to sdma_channel object
+ * @context:	pointer to context data to load
+ *
+ * Loads arbitrary data into the channel's context RAM. Does not configure any
+ * Linux DMA state.
+ *
+ * Return: 0 on success, nonzero on error
+ */
+int sdma_load_context_raw(struct sdma_channel *sdmac,
+		struct sdma_context_data *context);
+
+/**
+ * sdma_load_partial_context() - writes a subset of a channel's context
+ * @sdmac:		pointer to sdma_channel object
+ * @context:		pointer to data to write
+ * @byte_offset:	destination offset within the channel's context RAM
+ *			(must be a multiple of 4 and less than 128)
+ * @num_bytes:		number of bytes to copy into the channel's context RAM
+ *			(must be > 0 and <= 128)
+ *
+ * Can be used to update a subset of a channel's registers while leaving others
+ * undisturbed, e.g. to change a script's arguments while it is running without
+ * overwriting internal state.
+ * Since RAM loading is handled by channel 0, and channels cannot preempt each
+ * other, the load operation is mutually exclusive with the channel's execution.
+ * (i.e. a channel's registers will not change while its script is executing.)
+ *
+ * Example: to update a channel's entire context, use byte_offset=0 and
+ * num_bytes=128.
+ *
+ * Return: 0 on success, nonzero on error
+ */
+int sdma_load_partial_context(struct sdma_channel *sdmac,
+	struct sdma_context_data *context,
+	u32 byte_offset,
+	u32 num_bytes);
+
+/* size should be a value in bytes */
+/* address should be in data space (word addressing) */
+
+/**
+ * sdma_write_datamem() - writes data into the SDMA engine's address space
+ * @sdma:	pointer to sdma_engine object
+ * @buf:	data to write
+ * @size:	number of bytes to write
+ * @address:	destination offset, in 32-bit words, from the origin of SDMA
+ *		address space
+ *
+ * Return: 0 on success, nonzero on error
+ */
+int sdma_write_datamem(struct sdma_engine *sdma, void *buf, int size,
+	u32 address);
+
+/**
+ * sdma_fetch_datamem() - reads data from the SDMA engine's address space
+ * @sdma:	pointer to sdma_engine object
+ * @buf:	buffer to receive data
+ * @size:	number of bytes to read
+ * @address:	source offset, in 32-bit words, from the origin of SDMA address
+ *		space
+ *
+ * Return: 0 on success, nonzero on error
+ */
+int sdma_fetch_datamem(struct sdma_engine *sdma, void *buf, int size,
+	u32 address);
+
+/**
+ * sdma_fetch_partial_context() - reads a subset of a channel's context
+ * @sdmac:		pointer to sdma_channel object
+ * @buf:		buffer to receive data
+ * @byte_offset:	source offset within the channel's context RAM
+ *			(must be a multiple of 4 and less than 128)
+ * @num_bytes:		number of bytes to read from the channel's context RAM
+ *			(must be > 0 and <= 128)
+ *
+ * Since RAM loading is handled by channel 0, and channels cannot preempt each
+ * other, the fetch operation is mutually exclusive with the channel's
+ * execution. (i.e. the values will not be changing at the same time as they are
+ * being read.)
+ *
+ * Example: to fetch a channel's entire context, use byte_offset=0 and
+ * num_bytes=128.
+ *
+ * buf must be large enough to hold num_bytes of data.
+ *
+ * Return: 0 on success, nonzero on error
+ */
+int sdma_fetch_partial_context(struct sdma_channel *sdmac, void *buf,
+    u32 byte_offset,
+    u32 num_bytes);
+
+/**
+ * sdma_channel_context_base() - get the address of a channel's context RAM
+ * @ch:		channel number, 0-31
+ *
+ * Return: offset from SDMA address space origin in 32-bit words
+ */
+u32 sdma_channel_context_base(int ch);
+
+/**
+ * sdma_print_context() - dump string representation of channel context values
+ * @sdma:	pointer to sdma_engine object
+ * @channel:	channel number, 0-31
+ * @buf:	buffer to receive the string
+ *
+ * Prints a string representation of all channel registers and scratch memory
+ * words. buf should be at least 512 bytes long. Useful for debugging.
+ *
+ * Return: result string length in bytes, or < 0 on error
+ */
+ssize_t sdma_print_context(struct sdma_engine *sdma, int channel, char *buf);
+
 #endif /* __MACH_MXC_SDMA_H__ */
